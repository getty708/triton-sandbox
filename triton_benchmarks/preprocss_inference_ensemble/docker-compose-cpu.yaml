services:
  tritonserver:
    build:
      context: ./docker
      dockerfile: Dockerfile
      target: triton_sandbox_cpu
    image: getty708/triton-sandbox:24.01-py3-cpu-benchmark-ensemble
    container_name: triton-benchmark-ensemble
    working_dir: /workspace/triton-sandbox/triton_benchmarks/preprocss_inference_ensemble
    command: /bin/bash
    tty: true
    volumes:
      - ../../:/workspace/triton-sandbox
    environment:
      PYTHONPATH: /workspace/triton-sandbox
      TF_ENABLE_ONEDNN_OPTS: 0
    shm_size: 32g
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
